<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="description" content="Texturify: Generating Textures on 3D Shape Surfaces">
    <meta name="keywords" content="Texurify, GAN, 3D textures, textures, stylegan">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Texturify: Generating Textures on 3D Shape Surfaces</title>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">

    <style>
		.render_wrapper {
			position: relative;
            height: 300px;
         }
        .render_wrapper_small {
			position: relative;
            height: 200px;
         }
		.render_div {
			position: absolute;
			top: 0;
			left: 0;
		}

        #interpolation-image-wrapper-car{
            text-align: center;
        }
        #interpolation-image-wrapper-chair{
            text-align: center;
        }
        .nested-columns {
            margin-bottom: 0 !important;
        }
    </style>

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
</head>

<body>

    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">Texturify: Generating Textures on 3D Shape Surfaces</h1>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <a href="https://niessnerlab.org/members/yawar_siddiqui/profile.html">Yawar Siddiqui</a><sup>1</sup>,</span>
                            <span class="author-block">
                                <a href="https://justusthies.github.io/">Justus Thies</a><sup>2</sup>,</span>
                            <span class="author-block">
                                <a href="https://fangchangma.github.io/">Fangchang Ma</a><sup>3</sup>,
                            </span>
                            <span class="author-block">
                                <a href="http://shanqi.github.io/">Qi Shan</a><sup>3</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://niessnerlab.org/members/matthias_niessner/profile.html">Matthias
                                    Nie√üner</a><sup>1</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://www.3dunderstanding.org/team.html">Angela Dai</a><sup>1</sup>,
                            </span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block"><sup>1</sup>Technical University of Munich,</span>
                            <span class="author-block"><sup>2</sup>Max Planck Institute for Intelligent Systems,</span>
                            <span class="author-block"><sup>3</sup>Apple</span>
                        </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <!-- PDF Link. -->
                                <span class="link-block">
                                    <a href="static/Texturify.pdf"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>Paper</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="ai ai-arxiv"></i>
                                        </span>
                                        <span>arXiv</span>
                                    </a>
                                </span>
                                <!-- Video Link. -->
                                <span class="link-block">
                                    <a href="#"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <svg class="svg-inline--fa fa-youtube fa-w-18" aria-hidden="true"
                                                focusable="false" data-prefix="fab" data-icon="youtube" role="img"
                                                xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"
                                                data-fa-i2svg="">
                                                <path fill="currentColor"
                                                    d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z">
                                                </path>
                                            </svg><!-- <i class="fab fa-youtube"></i> Font Awesome fontawesome.com -->
                                        </span>
                                        <span>Video</span>
                                    </a>
                                </span>


                                <!-- Github Link. -->
                                <span class="link-block">
                                    <a class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code (coming soon)</span>
                                    </a>
                                </span>
                                <!-- Dataset Link. -->
                                <span class="link-block"></span>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="hero teaser">
        <div class="container is-max-desktop">
            <div class="hero-body">
                <img src="./static/teaser/teaser.jpg" height="150%" />
                <h2 class=" subtitle has-text-centered" style="padding-top: 10px">
                    <span class="dnerf">Texturify</span> learns to generate geometry-aware textures for untextured collections of 3D objects. Our method trains from only a collection of images and a collection of untextured shapes, which are both often available, without requiring any explicit 3D color supervision or shape-image correspondence. Textures are created directly on the surface of a given 3D shape, enabling generation of high-quality, compelling textured 3D shapes.
                </h2>
            </div>
        </div>
    </section>


    <section class="hero is-light is-small">
        <div class="hero-body">
            <div class="container">
                <div id="results-carousel" class="carousel results-carousel">
                    <div class="item item-steve render_wrapper">
			            <div id="mesh_chair_0" class="render_div"></div>
                    </div>
                    <div class="item item-steve render_wrapper">
			            <div id="mesh_chair_1" class="render_div"></div>
                    </div>
                    <div class="item item-steve render_wrapper">
			            <div id="mesh_chair_2" class="render_div"></div>
                    </div>
                    <div class="item item-steve render_wrapper">
			            <div id="mesh_chair_3" class="render_div"></div>
                    </div>
                    <div class="item item-steve render_wrapper">
			            <div id="mesh_car_0" class="render_div"></div>
                    </div>
                    <div class="item item-steve render_wrapper">
			            <div id="mesh_car_1" class="render_div"></div>
                    </div>
                    <div class="item item-steve render_wrapper">
			            <div id="mesh_car_2" class="render_div"></div>
                    </div>
                    <div class="item item-steve render_wrapper">
			            <div id="mesh_car_3" class="render_div"></div>
                    </div>
                </div>
                <div style="text-align: center;">Press <b>G</b> to toggle between geometry and <span class="dnerf">Texturified</span> meshes. Press <b>R</b> to reset view. </div>
            </div>
        </div>
    </section>


    <section class="section">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>
                        Texture cues on 3D objects are key to compelling visual representations, with the possibility to create high visual fidelity with inherent spatial consistency across different views.
                        Since the availability of textured 3D shapes remains very limited, learning a 3D-supervised data-driven method that predicts a texture based on the 3D input is very challenging.
                        </p>
                        <p>
                        We thus propose Texurify, a GAN-based method that leverages a 3D shape dataset of an object class and learns to reproduce the distribution of appearances observed in real images by generating high-quality textures.
                        </p>
                        <p>
                        In particular, our method does not require any 3D color supervision or correspondence between shape geometry and images to learn the texturing of 3D objects.
                        Texurify operates directly on the surface of the 3D objects by introducing face convolutional operators on a hierarchical 4-RoSy parameterization to generate plausible object-specific textures.
                        Employing differentiable rendering and adversarial losses that critique individual views and consistency across views, we effectively learn the high-quality surface texturing distribution from real-world images.
                        </p>
                        <p>
                        Experiments on car and chair shape collections show that our approach outperforms state of the art by an average of 22% in FID score.
                        </p>
                    </div>
                </div>
            </div>
            <!-- Paper video. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Video</h2>
                    <div class="publication-video">
                        <iframe src="https://www.youtube.com/embed/mDcsSK3GaF4" title="YouTube video player"
                            frameborder="0"
                            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                            allowfullscreen></iframe>
                    </div>
                </div>
            </div>
            <!--/ Paper video. -->
        </div>
    </section>


    <section class="section">
        <div class="container is-max-desktop">

            <h3 class="title is-4">Latent Interpolation</h3>
            <div class="content has-text-justified">
                <p>
                    The texture latent space learned by our method produces smoothly-varying valid textures when traversing across the latent space for a fixed shape.
                </p>
            </div>
            <div class="columns is-vcentered" style="margin-top: 10px">
                <div class="column columns nested-columns is-vcentered interpolation-panel">
                    <div class="column is-3 has-text-centered">
                        <img src="./static/latent_interpolation/chair/000.jpg"
                             class="interpolation-image"
                             alt="Interpolate start reference image."/>
                        <p>Start Frame</p>
                    </div>
                    <div class="column interpolation-video-column">
                        <div id="interpolation-image-wrapper-chair">
                          Loading...
                        </div>
                        <input class="slider is-fullwidth is-large is-info"
                               id="interpolation-slider-chair"
                               step="1" min="0" max="100" value="0" type="range">
                    </div>
                    <div class="column is-3 has-text-centered">
                        <img src="./static/latent_interpolation/chair/025.jpg"
                             class="interpolation-image"
                             alt="Interpolation end reference image."/>
                        <p class="is-bold">End Frame</p>
                    </div>
                </div>

                <div class="column columns nested-columns is-vcentered interpolation-panel" style="margin-left: 20px">
                    <div class="column is-3 has-text-centered">
                        <img src="./static/latent_interpolation/car/000.jpg"
                             class="interpolation-image"
                             alt="Interpolate start reference image."/>
                        <p>Start Frame</p>
                    </div>
                    <div class="column interpolation-video-column">
                        <div id="interpolation-image-wrapper-car">
                          Loading...
                        </div>
                        <input class="slider is-fullwidth is-large is-info"
                               id="interpolation-slider-car"
                               step="1" min="0" max="100" value="0" type="range">
                    </div>
                    <div class="column is-3 has-text-centered">
                        <img src="./static/latent_interpolation/car/025.jpg"
                             class="interpolation-image"
                             alt="Interpolation end reference image."/>
                        <p class="is-bold">End Frame</p>
                    </div>
                </div>
            </div>
            <!-- Novel datasets. -->
            <div class="columns is-centered" style="margin-top: 25px">
                <div class="column is-full-width">
                    <h2 class="title is-4">Style Consistency</h2>
                    <div class="content has-text-justified">
                        <p>
                            The learned latent space is consistent in style across different shapes, i.e. the same code represents a similar style across shapes, and can be used, for example, in style transfer applications.
                        </p>
                    </div>
                    <div class="columns is-centered">
                        <div class="column is-2">
                            <div class="buttons is-centered" style="height: 100%">
                              <button class="button" id="style_button_0" style="background-color: #0a0a0a; color: #d5d5d5">Style 1</button>
                              <button class="button" id="style_button_1" style="background-color: #d3bb90; color: #0a0a0a">Style 2</button>
                              <button class="button" id="style_button_2" style="background-color: #c6d576; color: #0a0a0a">Style 3</button>
                            </div>
                        </div>
                        <div class="column" style="background-color: #f5f5f5; margin-left: -5px;">
                            <div class="item item-steve render_wrapper_small">
                                <div id="mesh_style_0" class="render_div"></div>
                            </div>
                        </div>
                        <div class="column" style="background-color: #f5f5f5; margin-left: 5px;">
                            <div class="item item-steve render_wrapper_small">
                                <div id="mesh_style_1" class="render_div"></div>
                            </div>
                        </div>
                        <div class="column" style="background-color: #f5f5f5; margin-left: 5px;">
                            <div class="item item-steve render_wrapper_small">
                                <div id="mesh_style_2" class="render_div"></div>
                            </div>
                        </div>
                        <div class="column" style="background-color: #f5f5f5; margin-left: 5px;">
                            <div class="item item-steve render_wrapper_small">
                                <div id="mesh_style_3" class="render_div"></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            <!--/ Animation. -->

            <!-- Overview. -->
            <div class="columns is-centered" style="margin-top: 15px">
                <div class="column is-full-width">
                    <h2 class="title is-4">Method Overview</h2>
                    <img src="./static/teaser/overview.jpg"/>
                    <div class="content has-text-justified" style="padding-top: 15px">
                        <p>Surface features from an input 3D mesh are encoded through a face convolution-based encoder and decoded through a StyleGAN2-inspired decoder to generate textures directly on the surface of the mesh.</p>
                        <p>To ensure that generated textures are realistic, the textured mesh is differentiably rendered from different view points and is critiqued by two discriminators.</p>
                        <p>An image discriminator D<sub>I</sub> operates on full image views from the real or rendered views, while a patch-consistency discriminator D<sub>P</sub> encourages consistency between views by operating on patches coming from a single real view or patches from different views of rendered images.</p>
                    </div>

                </div>
            </div>

            <!--
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Method Overview</h2>
                </div>
            </div>
            <section class="hero teaser">
                <div class="container is-max-desktop">
                    <div class="hero-body">
                        <img src="./static/teaser/overview.jpg"/>
                    </div>
                </div>
            </section>
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <div class="content has-text-justified">
                        <p>Surface features from an input 3D mesh are encoded through a face convolution-based encoder and decoded through a StyleGAN2-inspired decoder to generate textures directly on the surface of the mesh.</p>
                        <p>To ensure that generated textures are realistic, the textured mesh is differentiably rendered from different view points and is critiqued by two discriminators.</p>
                        <p>An image discriminator D<sub>I</sub> operates on full image views from the real or rendered views, while a patch-consistency discriminator D<sub>P</sub> encourages consistency between views by operating on patches coming from a single real view or patches from different views of rendered images.</p>
                    </div>
                </div>
            </div>
            -->

            <!-- Concurrent Work. -->
            <div class="columns is-centered">
                <div class="column is-full-width">
                    <h2 class="title is-3">Related Links</h2>

                    <div class="content has-text-justified">
                        <p>
                            For more work on similar tasks, please check out
                        </p>
                        <p>
                            <a href="https://www.bmvc2021-virtualconference.com/assets/papers/0271.pdf">Learning Texture Generators for 3D Shape
Collections from Internet Photo Sets</a> learns a texture generator for 3D objects from 2D image collections using a common UV parameterization.
                        </p>

                        <p>
                            <a href="https://avg.is.mpg.de/publications/oechsle2019iccv">Texture Fields: Learning Texture Representations in Function Space</a>
                            learns a texture generator parameterized as an implicit field.
                        </p>

                        <p>
                            <a href="https://arxiv.org/abs/2006.14660">SPSG: Self-Supervised Photometric Scene Generation from RGB-D Scans</a> tackles scene completion both in terms of geometry and texture using a 3D grid parameterization.
                        </p>

                        <p>
                            <a href="https://threedle.github.io/text2mesh/">Text2Mesh: Text-Driven Neural Stylization for Meshes</a> optimizes color and geometric details over a variety of source meshes, driven by a target text prompt.
                        </p>

                        <p>
                            <a href="https://arxiv.org/abs/1812.00020">TextureNet: Consistent Local Parametrizations for Learning from High-Resolution Signals on Meshes</a>, our motivation for using 4-RoSy parameterization, introduces a neural network architecture designed to extract features from high-resolution signals associated with 3D surface meshes, and show its application on point cloud segmentation.
                        </p>
                    </div>
                </div>
            </div>
            <!--/ Concurrent Work. -->

        </div>
    </section>

    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">BibTeX</h2>
            <pre>
                <code>
                    // to be added
                </code>
            </pre>
        </div>
    </section>


    <footer class="footer">
        <div class="container">
            <div class="content has-text-centered">
                <a class="icon-link" href="static/Texturify.pdf">
                    <i class="fas fa-file-pdf"></i>
                </a>
                <a class="icon-link" href="https://github.com/nihalsid" class="external-link" disabled>
                    <i class="fab fa-github"></i>
                </a>
            </div>
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">
                        <p style="text-align:center">
                            Source code mainly borrowed from <a href="https://keunhong.com/">Keunhong Park</a>'s <a
                                href="https://nerfies.github.io/">Nerfies website</a>.
                        </p>
                        <p style="text-align:center">
                            Please contact <a href="https://niessnerlab.org/members/yawar_siddiqui/profile.html">Yawar Siddiqui</a> for feedback and questions.
                        </p>

                    </div>
                </div>
            </div>
        </div>
    </footer>

    <!-- Import maps polyfill -->
    <!-- Remove this when import maps will be widely supported -->
    <script async src="https://unpkg.com/es-module-shims@1.3.6/dist/es-module-shims.js"></script>

    <script type="importmap">
        {
            "imports": {
                "three": "./js/three.module.js"
            }
        }
    </script>

    <script type="module">

        import * as THREE from 'three';

        import { PLYLoader } from './js/PLYLoader.js';
        import { OrbitControls } from './js/OrbitControls.js'
        let div_to_scene = {
            "mesh_chair_0": {
                "geo": null,
                "color": null,
            },
            "mesh_chair_1": {
                "geo": null,
                "color": null,
            },
            "mesh_chair_2": {
                "geo": null,
                "color": null,
            },
            "mesh_chair_3": {
                "geo": null,
                "color": null,
            },
            "mesh_car_0": {
                "geo": null,
                "color": null,
            },
            "mesh_car_1": {
                "geo": null,
                "color": null,
            },
            "mesh_car_2": {
                "geo": null,
                "color": null,
            },
            "mesh_car_3": {
                "geo": null,
                "color": null,
            }
        }
        let div_to_render_scene = {
            "mesh_style_0": {
                "0": null,
                "1": null,
                "2": null,
                "geo": null,
            },
            "mesh_style_1": {
                "0": null,
                "1": null,
                "2": null,
                "geo": null,
            },
            "mesh_style_2": {
                "0": null,
                "1": null,
                "2": null,
                "geo": null,
            },
            "mesh_style_3": {
                "0": null,
                "1": null,
                "2": null,
                "geo": null,
            },
        }
        let mouse_button_down = false;
        let list_of_orbit_controls = []
        let style_camera = null;
        let render_colors = true;
        let style_id = "0"

        function setup_camera(div_name){
            let container = document.getElementById(div_name);
            let width = container.parentElement.clientWidth;
            let height = container.parentElement.clientHeight;
            console.log(width, height)
            let camera = new THREE.PerspectiveCamera( 35, width / height, 0.1, 50 );
            let camera_init_position = new THREE.Vector3( -1.5, 0.35, 1.2 );
            if (div_name.includes("chair")){
                camera_init_position = camera_init_position.multiplyScalar(1.5)
            }
            else if (div_name.includes("style")) {
                camera_init_position = camera_init_position.multiplyScalar(1.25)
            }
            camera.position.set(camera_init_position.x, camera_init_position.y, camera_init_position.z);
            return camera;
        }

        function setup_render_divs(div_name, mesh_path){
            let camera = setup_camera(div_name)
            let orbit_control = create_render_div(camera, div_name, mesh_path)
            list_of_orbit_controls.push(orbit_control)
        }

        function setup_style_render_divs(div_name, mesh_path){
            if (style_camera == null) {
                style_camera = setup_camera(div_name)
            }
            let orbit_control = create_style_render_div(style_camera, div_name, mesh_path, true)
            list_of_orbit_controls.push(orbit_control)
            document.getElementById("style_button_0").addEventListener("click", set_style_0)
            document.getElementById("style_button_1").addEventListener("click", set_style_1)
            document.getElementById("style_button_2").addEventListener("click", set_style_2)
        }

        function create_render_div(camera, div_id, mesh_path) {
            let container;
            let renderer, controls;

            init();
            animate();

            function init() {

                container = document.getElementById(div_id);
                let width = container.parentElement.clientWidth;
                let height = container.parentElement.clientHeight;


                div_to_scene[div_id]["color"] = new THREE.Scene();
                div_to_scene[div_id]["geo"] = new THREE.Scene();
                div_to_scene[div_id]["color"].background = new THREE.Color( 0xffffff );
                div_to_scene[div_id]["geo"].background = new THREE.Color( 0xffffff );

                // PLY file

                const loader = new PLYLoader();
                loader.load( mesh_path, function ( geometry ) {

                    geometry.computeVertexNormals();
                    let material_color = new THREE.MeshBasicMaterial( { color: 0xffffff, vertexColors: THREE.VertexColors} );
                    let material_geo = new THREE.MeshStandardMaterial( { color: 0x444444, flatShading: true } )


                    const mesh_color = new THREE.Mesh( geometry, material_color );
                    const mesh_geo = new THREE.Mesh( geometry, material_geo );

                    div_to_scene[div_id]["color"].add( mesh_color );
                    div_to_scene[div_id]["geo"].add( mesh_geo );

                }, (xhr) => {
                    console.log((xhr.loaded / xhr.total) * 100 + '% loaded')
                }, (error) => {
                    console.log(error)
                }
                );

                // lights

                div_to_scene[div_id]["geo"].add( new THREE.HemisphereLight( 0x333333, 0x222222 ) );
                addShadowedLight(div_to_scene[div_id]["geo"], 1, 1, 1, 0xffffff, 1.35 );
                addShadowedLight(div_to_scene[div_id]["geo"],  0.5, 1, - 1, 0xffffff, 1 );

                // renderer

                renderer = new THREE.WebGLRenderer( { antialias: true } );
                renderer.setPixelRatio( window.devicePixelRatio );
                renderer.setSize( width, height);
                renderer.outputEncoding = THREE.sRGBEncoding;

                renderer.shadowMap.enabled = true;

                container.appendChild( renderer.domElement );

                controls = new OrbitControls(camera, renderer.domElement)
                controls.enableDamping = false

                // resize

                window.addEventListener( 'resize', onWindowResize );

        }
            function onWindowResize() {
                let width = container.clientWidth;
                let height = container.clientHeight;
                camera.aspect = width / height;
                camera.updateProjectionMatrix();
                renderer.setSize( width, height );
            }
            function animate() {
                requestAnimationFrame( animate );
                render();
            }

            function render() {
                renderer.render( div_to_scene[div_id][render_colors ? "color" : "geo"], camera );
                controls.update();
            }

            return controls;
        }

        function create_style_render_div(camera, div_id, mesh_path) {
            let container;
            let renderer, controls;

            init();
            animate();

            function init() {

                container = document.getElementById(div_id);
                let width = container.parentElement.clientWidth;
                let height = container.parentElement.clientHeight;


                div_to_render_scene[div_id]["0"] = new THREE.Scene();
                div_to_render_scene[div_id]["1"] = new THREE.Scene();
                div_to_render_scene[div_id]["2"] = new THREE.Scene();
                div_to_render_scene[div_id]["0"].background = new THREE.Color( 0xffffff );
                div_to_render_scene[div_id]["1"].background = new THREE.Color( 0xffffff );
                div_to_render_scene[div_id]["2"].background = new THREE.Color( 0xffffff );
                div_to_render_scene[div_id]["geo"] = new THREE.Scene();
                div_to_render_scene[div_id]["geo"].background = new THREE.Color( 0xffffff );

                // PLY file

                const loader = new PLYLoader();
                ["0", "1", "2"].forEach(id => {
                    loader.load( mesh_path + id + ".ply", function ( geometry ) {
                        geometry.computeVertexNormals();
                        let material = new THREE.MeshBasicMaterial( { color: 0xffffff, vertexColors: THREE.VertexColors} );
                        const mesh_color = new THREE.Mesh( geometry, material );
                        div_to_render_scene[div_id][id].add( mesh_color );
                        if (id === "0") {
                            let material_geo = new THREE.MeshStandardMaterial( { color: 0x444444, flatShading: true } )
                            const mesh_geo = new THREE.Mesh( geometry, material_geo );
                            div_to_render_scene[div_id]["geo"].add( mesh_geo );
                        }
                    }, (xhr) => {
                        console.log((xhr.loaded / xhr.total) * 100 + '% loaded')
                    }, (error) => {
                        console.log(error)
                    }
                    );
                })

                div_to_render_scene[div_id]["geo"].add( new THREE.HemisphereLight( 0x333333, 0x222222 ) );
                addShadowedLight(div_to_render_scene[div_id]["geo"], 1, 1, 1, 0xffffff, 1.35 );
                addShadowedLight(div_to_render_scene[div_id]["geo"],  0.5, 1, - 1, 0xffffff, 1 );

                // renderer

                renderer = new THREE.WebGLRenderer( { antialias: true } );
                renderer.setPixelRatio( window.devicePixelRatio );
                renderer.setSize( width, height);
                renderer.outputEncoding = THREE.sRGBEncoding;

                renderer.shadowMap.enabled = true;

                container.appendChild( renderer.domElement );

                controls = new OrbitControls(camera, renderer.domElement)
                controls.enableDamping = false

                // resize

                window.addEventListener( 'resize', onWindowResize );

        }
            function onWindowResize() {
                let width = container.clientWidth;
                let height = container.clientHeight;
                camera.aspect = width / height;
                camera.updateProjectionMatrix();
                renderer.setSize( width, height );
            }
            function animate() {
                requestAnimationFrame( animate );
                render();
            }

            function render() {
                let scene = render_colors ? div_to_render_scene[div_id][style_id]: div_to_render_scene[div_id]["geo"]
                renderer.render( scene, camera );
                controls.update();
            }

            return controls;
        }

        function addShadowedLight(scene, x, y, z, color, intensity ) {

            const directionalLight = new THREE.DirectionalLight( color, intensity );
            directionalLight.position.set( x, y, z );
            scene.add( directionalLight );

            directionalLight.castShadow = true;

            const d = 1;
            directionalLight.shadow.camera.left = - d;
            directionalLight.shadow.camera.right = d;
            directionalLight.shadow.camera.top = d;
            directionalLight.shadow.camera.bottom = - d;

            directionalLight.shadow.camera.near = 1;
            directionalLight.shadow.camera.far = 4;

            directionalLight.shadow.mapSize.width = 1024;
            directionalLight.shadow.mapSize.height = 1024;

            directionalLight.shadow.bias = - 0.001;

        }

        document.addEventListener('keydown', logKey);

        function logKey(evt) {
            if (evt.keyCode === 71 && !mouse_button_down) {
                switch_geometry()
            }
            if (evt.keyCode === 82 && !mouse_button_down) {
                reset_orbit_controls()
            }
        }

        function switch_geometry() {
            render_colors = !render_colors
        }

        function reset_orbit_controls() {
            list_of_orbit_controls.forEach(oc => {
                oc.reset()
            })
        }

        function set_style_0(){
            style_id = "0"
        }

        function set_style_1(){
            style_id = "1"
        }

        function set_style_2(){
            style_id = "2"
        }

        document.body.onmousedown = function(evt) {
            if (evt.button === 0)
                mouse_button_down = true
        }
        document.body.onmouseup = function(evt) {
            if (evt.button === 0)
                mouse_button_down = false
        }

        window.onload = function() {
            let slider = document.getElementsByClassName("slider")[0]
            slider.removeAttribute("tabIndex")
            // slider.addEventListener("mouseout", reset_orbit_controls);
            setup_render_divs("mesh_chair_0", './models/chair_01328.ply')
            setup_render_divs("mesh_chair_1", './models/chair_00009.ply')
            setup_render_divs("mesh_chair_2", './models/chair_00889.ply')
            setup_render_divs("mesh_chair_3", './models/chair_01829.ply')
            setup_render_divs("mesh_car_0", './models/car_00265.ply')
            setup_render_divs("mesh_car_1", './models/car_00742.ply')
            setup_render_divs("mesh_car_2", './models/car_00848.ply')
            setup_render_divs("mesh_car_3", './models/car_00944.ply')
            setup_style_render_divs("mesh_style_0", './models/chair_style_0')
            setup_style_render_divs("mesh_style_1", './models/chair_style_1')
            setup_style_render_divs("mesh_style_2", './models/chair_style_2')
            setup_style_render_divs("mesh_style_3", './models/chair_style_3')
        };

    </script>
</body>

</html>